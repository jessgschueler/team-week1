{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from exif import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import glob\n",
    "import csv\n",
    "\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "# onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "meta_data = \"data/meta_data.csv\"\n",
    "meta_df = pd.read_csv(meta_data, header=0)\n",
    "\n",
    "# from pandas.util import hash_pandas_object\n",
    "\n",
    "# hash_pandas_object(meta_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exif import Image\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "from csv import DictWriter\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# directory = \"./images\"\n",
    "# filepaths = []\n",
    "# for image in os.listdir(directory):\n",
    "#     i = os.path.join(directory, image)\n",
    "#     if os.path.isfile(i):\n",
    "#         filepaths.append(i)\n",
    "#     return filepaths\n",
    "\n",
    "# image_input = []\n",
    "\n",
    "# if image.endswith(\".jpg\"): \n",
    "#     img = Image.open(image)\n",
    "#     file_name, file_ext = os.path.splitext(image)\n",
    "#     img.save('/png/{}.png'.format(file_name))\n",
    "#     os.rename(image_input, image_input.split('.')[0]+'.jpg')\n",
    "#     print(image_input)\n",
    "\n",
    "# directory = \"./images\"\n",
    "#     filepaths = []\n",
    "#     for image in os.listdir(directory):\n",
    "#         i = os.path.join(directory, image)\n",
    "#         if os.path.isfile(i):\n",
    "#             filepaths.append(i)\n",
    "#     return filepaths\n",
    "# images_folder = os.listdir('images')\n",
    "# # img = open(images_folder)\n",
    "# image_input = []\n",
    "\n",
    "# for image in images_folder \n",
    "#     glob.glob('*.jpg'):\n",
    "#     image_input.append(file)\n",
    "#     image_input\n",
    "\n",
    "# or a shorter way \n",
    "# image_input = [f for f in greturnlob.glob(\"*.txt\")]\n",
    "# # This method returns current working directory of a process.\n",
    "\n",
    "# # path = '/some/path/to/file'\n",
    "# # for filename in glob.glob(os.path.join(path, '*.txt')):\n",
    "# #    with open(os.path.join(os.getcwd(), filename), 'r') as f: # open in readonly mode\n",
    "# #       # do your stuff\n",
    "#     #   print \"Current working dir : %s\" % os.getcwd()\n",
    "# for filename in glob.glob(os.path.join(images_folder, '*,jpg')):\n",
    "#     with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
    "    \n",
    "#         if filename.endswith('.jpg'):\n",
    "#             image_input = image_input.append(filename)\n",
    "\n",
    "#         else: \n",
    "#             # file_name, file_ext = os.path.splitext(image)\n",
    "#             # img.save('/png/{}.png'.format(file_name))\n",
    "#             os.rename(image_input, image_input.split('.')[0]+'.jpg')\n",
    "#             image_input = image_input.append(filename)\n",
    "# return image_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('./images/tj_food', '.jpg')\n",
      "('./images/IMG_7690', '.jpeg')\n",
      "('./images/20220411_075008', '.jpg')\n",
      "('./images/IMG_8154', '.jpeg')\n",
      "('./images/IMG_8608', '.jpg')\n",
      "('./images/20211204_231330', '.jpg')\n",
      "('./images/0331191922a_HDR', '.jpg')\n",
      "('./images/IMG_20170413_165525732', '.jpg')\n",
      "('./images/20220215_143240', '.jpg')\n",
      "('./images/IMG_5324', '.jpeg')\n",
      "('./images/IMG_8261', '.jpeg')\n",
      "('./images/0210212338a', '.jpg')\n",
      "('./images/IMG_6523', '.jpeg')\n",
      "('./images/oranges', '.jpg')\n",
      "('./images/sumo', '.jpg')\n",
      "('./images/stages', '.png')\n",
      "('./images/sesamestreet', '.jpg')\n",
      "('./images/hike', '.jpg')\n",
      "('./images/IMG_5145', '.jpeg')\n",
      "('./images/staples_center', '.jpg')\n",
      "('./images/IMG_7408', '.jpeg')\n",
      "('./images/IMG_6970', '.jpeg')\n",
      "('./images/medieval', '.jpg')\n",
      "('./images/IMG_7292', '.jpeg')\n",
      "('./images/20220308_153023', '.jpg')\n",
      "('./images/IMG_7673', '.jpeg')\n",
      "('./images/0514201057 (1)', '.jpg')\n",
      "('./images/20210405_133828', '.jpg')\n",
      "('./images/20211223_163030', '.jpg')\n",
      "('./images/20210425_031811', '.jpg')\n",
      "('./images/grasshopper', '.jpg')\n",
      "('./images/1213202230b~2', '.jpg')\n",
      "('./images/duma', '.jpg')\n",
      "('./images/IMG_8706', '.jpg')\n",
      "('./images/IMG_8687', '.jpg')\n",
      "('./images/IMG_6696', '.jpeg')\n",
      "('./images/0504211949', '.jpg')\n",
      "('./images/IMG_0470', '.jpg')\n",
      "('./images/20210903_222317', '.jpg')\n",
      "('./images/20210204_160056', '.jpg')\n",
      "('./images/olive', '.jpg')\n",
      "('./images/0122211534a_HDR', '.jpg')\n",
      "('./images/104B057B-3BF8-4610-BF33-A678EAB5380D', '.JPG')\n",
      "('./images/IMG_6212', '.jpeg')\n",
      "('./images/boat', '.jpg')\n",
      "('./images/20220326_040427', '.jpg')\n",
      "('./images/20220406_195101', '.jpg')\n",
      "('./images/IMG_5799', '.jpeg')\n",
      "('./images/0511211650a_HDR', '.jpg')\n",
      "('./images/museum', '.jpg')\n",
      "('./images/20211229_145410', '.jpg')\n",
      "('./images/20220426_110709', '.jpg')\n",
      "('./images/IMG_20170523_044545811', '.jpg')\n",
      "('./images/0201210007', '.jpg')\n",
      "('./images/20210204_192522', '.jpg')\n",
      "('./images/IMG_6816', '.jpeg')\n",
      "('./images/IMG_3143', '.jpeg')\n",
      "('./images/weird_tree', '.jpg')\n",
      "('./images/0602211537a_HDR', '.jpg')\n",
      "('./images/32B7B192-E638-4DA1-BE40-8F3D604BFD91', '.jpg')\n",
      "('./images/20220124_182220', '.jpg')\n",
      "('./images/IMG_5120', '.jpeg')\n",
      "('./images/IMG_20161225_104113125_HDR', '.jpg')\n",
      "('./images/9A861762-FC04-48B2-8856-011EFE860FD1', '.JPG')\n",
      "('./images/IMG_62722', '.jpeg')\n",
      "('./images/20220306_134640', '.jpg')\n",
      "('./images/IMG_0330', '.jpg')\n",
      "('./images/20210625_124524', '.jpg')\n",
      "('./images/haworthia', '.jpg')\n",
      "('./images/20220226_032601', '.jpg')\n",
      "('./images/IMG_8702', '.jpg')\n",
      "('./images/IMG_0036', '.jpg')\n",
      "('./images/axle', '.jpg')\n",
      "('./images/63875643497__9606A74B-2196-426D-9BD0-AE33C74BD2F9', '.jpeg')\n",
      "('./images/1226210348', '.gif')\n",
      "('./images/20220216_104802_01', '.jpg')\n",
      "('./images/20220410_223143', '.jpg')\n",
      "('./images/20211020_002637', '.jpg')\n",
      "('./images/20220423_193426', '.jpg')\n",
      "('./images/20210930_201145', '.jpg')\n",
      "('./images/IMG_8087', '.jpeg')\n",
      "('./images/IMG_0399', '.jpg')\n",
      "('./images/aero_garden', '.jpg')\n",
      "('./images/IMG_8613', '.jpg')\n",
      "('./images/bakery', '.jpg')\n",
      "('./images/1204211415i', '.jpg')\n",
      "('./images/20210426_174943', '.jpg')\n",
      "('./images/0122211534a_HDR.jpg:Zone', '.Identifier')\n",
      "('./images/20210718_202525', '.jpg')\n",
      "('./images/20220323_192522', '.jpg')\n",
      "('./images/IMG_0561', '.jpg')\n",
      "('./images/broom', '.jpg')\n",
      "('./images/20220308_155102', '.jpg')\n",
      "('./images/0511201730 (1)', '.jpg')\n",
      "('./images/20220217_130555', '.jpg')\n",
      "('./images/IMG_7922', '.jpeg')\n",
      "('./images/0508211212b', '.jpg')\n",
      "('./images/20220308_153843', '.jpg')\n",
      "('./images/IMG_2338', '.jpeg')\n",
      "('./images/art_selfie', '.jpg')\n",
      "('./images/botanical2', '.jpg')\n",
      "('./images/lake', '.jpg')\n",
      "('./images/pool', '.jpg')\n",
      "('./images/1213202230b', '.jpg')\n",
      "('./images/20211217_1730392', '.jpg')\n"
     ]
    }
   ],
   "source": [
    "def img_filepaths():\n",
    "    \"\"\"\n",
    "    Returns a list of all the file filepaths in our directory variable.\n",
    "    \"\"\"\n",
    "    directory = \"./images\"\n",
    "    filepaths = []\n",
    "    for image in os.listdir(directory):\n",
    "        i = os.path.join(directory, image)\n",
    "        if os.path.isfile(i):\n",
    "            filepaths.append(i)\n",
    "    return filepaths    \n",
    "filepaths = img_filepaths()\n",
    "\n",
    "for file in filepaths:\n",
    "    split = os.path.splitext(file)\n",
    "    print(split)\n",
    "# if file in filepaths:\n",
    "    # file_name, file_ext = os.path.splitext(filepaths)\n",
    "    # filepaths.save('/png/{}.png'.format(file_name))\n",
    "# split = os.path.split(filepaths)\n",
    "# print(split) \n",
    "\n",
    "# print(os.path.splitext(file_name)) \n",
    "# img = Image.open(image)\n",
    "#         file_name, file_ext = os.path.splitext(image)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def img_filepaths():\n",
    "    \"\"\"\n",
    "    Returns a list of all the file filepaths in our directory variable.\n",
    "    \"\"\"\n",
    "    directory = \"./images\"\n",
    "    filepaths = []\n",
    "\n",
    "    for image in os.listdir(directory):\n",
    "        i = os.path.join(directory, image)\n",
    "        # if os.path.isfile(i):\n",
    "        #     filepaths.append(i)\n",
    "        img = Image.open(image)\n",
    "        file_name, file_ext = os.path.splitext(image)\n",
    "        img.save('/png/{}.png'.format(file_name))\n",
    "        os.rename(image, image.split('.')[0]+'.jpg')\n",
    "        print(image)\n",
    "        \n",
    "        # for image in glob.glob('*.jpg'):\n",
    "        #     filepaths.append(i)\n",
    "                \n",
    "            # print(filepaths)\n",
    "    print(filepaths)\n",
    "# image_input = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# os.rename(image_input, image_input.split('.')[0]+'.jpg')\n",
    "# print(image_input)\n",
    "\n",
    "# from pathlib import Path\n",
    "# p = Path('mysequence.fasta')\n",
    "# p.rename(p.with_suffix('.aln'))\n",
    "\n",
    "\n",
    "# with open('meta_data.csv', newline='') as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     for row in reader:\n",
    "#         print(row)\n",
    "\n",
    "directory = \"images\"\n",
    "image = \"images.jpg\"\n",
    "def img_metachecker():\n",
    "    for image in os.listdir(directory):\n",
    "        try:\n",
    "            i = os.path.join(directory, image)\n",
    "            if os.path.isfile(i):\n",
    "                # print(i)\n",
    "                curr_image = Image(i)\n",
    "                print(dir(curr_image))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "img_metachecker()\n",
    "\n",
    "\n",
    "\n",
    "# #creating new folder\n",
    "# os.mkdir('/home/kolla/newfolder')\n",
    "# # for linux systems\n",
    "# os.system('cp /home/kolla/* /home/kolla/newfolder')\n",
    "\n",
    "# # Getting all the csv files in folder recursively\n",
    "# files = glob.glob('/home/kolla/newfolder/**/*', recursive=True)\n",
    "\n",
    "# for file in files:\n",
    "#      #renaming the file with .zip extension\n",
    "    \n",
    "    \n",
    "        \n",
    "\n",
    "# from collections import defaultdict\n",
    "\n",
    "# file_dict = defaultdict(list)\n",
    "# for filename in files:\n",
    "# #     file_dict[get_file_hash(filename)].append(filename)    \n",
    "\n",
    "# if file.endswith(\".jpg\"): \n",
    "#                     img = Image.open(file)\n",
    "#                     file_name, file_ext = os.path.splitext(file)\n",
    "#                     img.save('/png/{}.png'.format(file_name))\n",
    "# os.rename(image_input, image_input.split('.')[0]+'.jpg')\n",
    "# print(image_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    " \n",
    "# initialize a string\n",
    "str = \"www.MyTecBits.com\"\n",
    " \n",
    "# encode the string\n",
    "encoded_str = str.encode()\n",
    " \n",
    "# create a md5 hash object initialized with the encoded string\n",
    "hash_obj = hashlib.md5(encoded_str)\n",
    " \n",
    "# convert the hash object to a hexadecimal value\n",
    "hexa_value = hash_obj.hexdigest()\n",
    " \n",
    "# print\n",
    "print(\"\\n\", hexa_value, \"\\n\")\n",
    "\n",
    "# # compact version \n",
    "import hashlib\n",
    "hashlib.md5(f\"images.jpg\").hexdigest()\n",
    "hashlib.md5(b\"www.MyTecBits.com\").digest()\n",
    "\n",
    "# # As you have noticed, the above example returned the hash code as a hexadecimal value using the hexdigest() method. If you need to get the resultant hash code in byte value, then use the digest() method. Here is an example.\n",
    "\n",
    "\n",
    " \n",
    "# # create a md5 hash object\n",
    "# hash_object = hashlib.md5()\n",
    " \n",
    "# # append the byte string\n",
    "# hash_object.update(b\"www.\")\n",
    "# hash_object.update(b\"MyTecBits\")\n",
    "# hash_object.update(b\".com\")\n",
    " \n",
    "# print(\"\\n\", hash_object.hexdigest(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes file path as input. It returns hash value for each file as output. I am currently using md5 hashing algorithm here. you can use any other hashing algorithm of your choice.\n",
    "# You can also send block size as parameter. For example, For Big files, you just want to calculate hash value for only first few bytes of data rather than entire file. In that case, you can use the block size. When setting a value to blocksize, make sure to replace file.read() with file.read(block_size) in the below function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TileWidth</th>\n",
       "      <th>TileLength</th>\n",
       "      <th>GPSInfo</th>\n",
       "      <th>ResolutionUnit</th>\n",
       "      <th>ExifOffset</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Software</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>XResolution</th>\n",
       "      <th>YResolution</th>\n",
       "      <th>HostComputer</th>\n",
       "      <th>File Path</th>\n",
       "      <th>MD5 Hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>762.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>samsung</td>\n",
       "      <td>SM-G970U</td>\n",
       "      <td>G970USQS2BSIV</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019:11:16 15:17:09</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/tj_food.jpg</td>\n",
       "      <td>d1654cb2f80b9d713590ac1e386ea385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>Apple</td>\n",
       "      <td>iPhone XR</td>\n",
       "      <td>14.7.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>iPhone XR</td>\n",
       "      <td>./images/IMG_7690.jpeg</td>\n",
       "      <td>ed79d223357ec81af41f5c00fc449b44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>samsung</td>\n",
       "      <td>SM-G991U1</td>\n",
       "      <td>G991U1UES5CVCB</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/20220411_075008.jpg</td>\n",
       "      <td>72aed7a61cb2648be8b10ca5a2496ea5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>Apple</td>\n",
       "      <td>iPhone XR</td>\n",
       "      <td>14.8.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022:03:12 12:56:22</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>iPhone XR</td>\n",
       "      <td>./images/IMG_8154.jpeg</td>\n",
       "      <td>c879f14451fc6101af3df0d57770f713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/IMG_8608.jpg</td>\n",
       "      <td>b60d6c992bff4a508a8acc1584da5904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>samsung</td>\n",
       "      <td>SM-G970U</td>\n",
       "      <td>G970USQS5GUF1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021:09:03 13:19:49</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/botanical2.jpg</td>\n",
       "      <td>08193e274fc019e73da26adf26a8b3a7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>samsung</td>\n",
       "      <td>SM-G970U</td>\n",
       "      <td>G970USQU6GUJ3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021:12:25 15:11:12</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/lake.jpg</td>\n",
       "      <td>2512ca33262bd200f7604d14048c53cb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>samsung</td>\n",
       "      <td>SM-G900V</td>\n",
       "      <td>G900VVRU2DQL1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/pool.jpg</td>\n",
       "      <td>063af64b7acbe0ed88ebef6be3acbfa6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/1213202230b.jpg</td>\n",
       "      <td>3625f28647813949a8f197217c963284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>samsung</td>\n",
       "      <td>SM-G991U1</td>\n",
       "      <td>G991U1UEU4BUKF</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2021:12:17 17:30:39</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/20211217_1730392.jpg</td>\n",
       "      <td>96a81ea542eaf4560977c64381722cc8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TileWidth  TileLength  GPSInfo  ResolutionUnit  ExifOffset     Make  \\\n",
       "0          NaN         NaN    762.0             2.0       238.0  samsung   \n",
       "1          NaN         NaN      NaN             2.0       204.0    Apple   \n",
       "2          NaN         NaN      NaN             2.0       228.0  samsung   \n",
       "3          NaN         NaN      NaN             2.0       204.0    Apple   \n",
       "4          NaN         NaN      NaN             NaN         NaN      NaN   \n",
       "..         ...         ...      ...             ...         ...      ...   \n",
       "99         NaN         NaN      NaN             2.0       226.0  samsung   \n",
       "100        NaN         NaN      NaN             2.0       226.0  samsung   \n",
       "101        NaN         NaN   3152.0             2.0       238.0  samsung   \n",
       "102        NaN         NaN      NaN             NaN         NaN      NaN   \n",
       "103        NaN         NaN      NaN             2.0       228.0  samsung   \n",
       "\n",
       "         Model        Software  Orientation             DateTime  XResolution  \\\n",
       "0     SM-G970U   G970USQS2BSIV          6.0  2019:11:16 15:17:09         72.0   \n",
       "1    iPhone XR          14.7.1          1.0                  NaN         72.0   \n",
       "2    SM-G991U1  G991U1UES5CVCB          1.0                  NaN         72.0   \n",
       "3    iPhone XR          14.8.1          3.0  2022:03:12 12:56:22         72.0   \n",
       "4          NaN             NaN          NaN                  NaN          NaN   \n",
       "..         ...             ...          ...                  ...          ...   \n",
       "99    SM-G970U   G970USQS5GUF1          1.0  2021:09:03 13:19:49         72.0   \n",
       "100   SM-G970U   G970USQU6GUJ3          1.0  2021:12:25 15:11:12         72.0   \n",
       "101   SM-G900V   G900VVRU2DQL1          1.0                  NaN         72.0   \n",
       "102        NaN             NaN          NaN                  NaN          NaN   \n",
       "103  SM-G991U1  G991U1UEU4BUKF          6.0  2021:12:17 17:30:39         72.0   \n",
       "\n",
       "     YResolution HostComputer                      File Path  \\\n",
       "0           72.0          NaN           ./images/tj_food.jpg   \n",
       "1           72.0    iPhone XR         ./images/IMG_7690.jpeg   \n",
       "2           72.0          NaN   ./images/20220411_075008.jpg   \n",
       "3           72.0    iPhone XR         ./images/IMG_8154.jpeg   \n",
       "4            NaN          NaN          ./images/IMG_8608.jpg   \n",
       "..           ...          ...                            ...   \n",
       "99          72.0          NaN        ./images/botanical2.jpg   \n",
       "100         72.0          NaN              ./images/lake.jpg   \n",
       "101         72.0          NaN              ./images/pool.jpg   \n",
       "102          NaN          NaN       ./images/1213202230b.jpg   \n",
       "103         72.0          NaN  ./images/20211217_1730392.jpg   \n",
       "\n",
       "                             MD5 Hash  \n",
       "0    d1654cb2f80b9d713590ac1e386ea385  \n",
       "1    ed79d223357ec81af41f5c00fc449b44  \n",
       "2    72aed7a61cb2648be8b10ca5a2496ea5  \n",
       "3    c879f14451fc6101af3df0d57770f713  \n",
       "4    b60d6c992bff4a508a8acc1584da5904  \n",
       "..                                ...  \n",
       "99   08193e274fc019e73da26adf26a8b3a7  \n",
       "100  2512ca33262bd200f7604d14048c53cb  \n",
       "101  063af64b7acbe0ed88ebef6be3acbfa6  \n",
       "102  3625f28647813949a8f197217c963284  \n",
       "103  96a81ea542eaf4560977c64381722cc8  \n",
       "\n",
       "[104 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "\n",
    "meta_file = './data/meta_data.csv'\n",
    "meta_df = pd.read_csv(meta_file, header=0)\n",
    "\n",
    "import hashlib\n",
    "\n",
    "def calculate_hash_val(path, block_size=''):\n",
    "    image = open(path, 'rb')\n",
    "    hasher = hashlib.md5()\n",
    "    data = image.read()\n",
    "    while len(data) > 0:\n",
    "        hasher.update(data)\n",
    "        data = image.read()\n",
    "    image.close()\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "meta_df['MD5 Hash'] = meta_df['File Path'].map(calculate_hash_val)\n",
    "\n",
    "meta_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes one empty dictionary and one dictionary with all input files as key and their respective hash value(which we calculated using the above calculate_hash_val function)as their values . The function returns dic_unique without any duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find same named images and store them in \n",
    "\n",
    "# def find_unique_image(dic_unique, dict1):\n",
    "#     for key in dict1.keys():\n",
    "#         if key not in dic_unique:\n",
    "#             dic_unique[key] = dict1[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the unique files are identified, the final step is to delete the remaining duplicate files. The below function is used to delete the duplicates from input folder. it takes two inputs all_inps and unique_inps which contatins file paths and hash values respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Required imports and declarations\n",
    "\n",
    "# Please assign the complete input folder path to ‘input_image_path’ variable\n",
    "\n",
    "import datetime, os, sys, logging, hashlib\n",
    "from pathlib import Path\n",
    "# file system path that also offers methods to do systems calls on path objects\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "input_image_path = r'images.jpg'\n",
    "# for filename in files,\n",
    "input_image = [f for f in listdir(input_image_path) if isfile(join(input_image_path, f))]\n",
    "input_image = [os.path.join(input_image_path, x) for x in input_image]\n",
    "inp_dups = {}\n",
    "unique_inps = {}\n",
    "# print(input_image)\n",
    "print(inp_dups)\n",
    "print(unique_inps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the duplicate image_names\n",
    "\n",
    "def remove_duplicate_image(all_inps ,unique_inps):\n",
    "    for image_name in all_inps.keys():\n",
    "        if all_inps[image_name] in unique_inps and image_name!=unique_inps[all_inps[image_name]]:\n",
    "            os.remove(image_name)\n",
    "        elif all_inps[image_name] not in unique_inps:\n",
    "            os.remove(image_name)\n",
    "            \n",
    "        print(inp_dups)\n",
    "        print(unique_inps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using the above functions same for both Sequential and Parallel implementation. Please find the code below for both the methods respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmv_dup_process(input_image):\n",
    "    all_inps={}\n",
    "    inp_dups = {}\n",
    "    unique_inps = {}\n",
    "    for file_path in input_image:\n",
    "        if Path(file_path).exists():\n",
    "           image_hash = calculate_hash_val(file_path)\n",
    "           inp_dups[image_hash]=file_path\n",
    "           all_inps[file_path] = image_hash\n",
    "        else:\n",
    "            print('%s is not a valid path, please verify' % file_path)\n",
    "            sys.exit()\n",
    "    print(inp_dups)\n",
    "    print(unique_inps)\n",
    "    print(all_inps)\n",
    "    # find_unique_image(unique_inps, inp_dups)\n",
    "    # print(inp_dups)\n",
    "    # remove_duplicate_image(all_inps, unique_inps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METHOD1(Sequential Implementation)\n",
    "def rmv_dup_process(input_image):\n",
    "    all_inps={}\n",
    "    for file_path in input_image:\n",
    "        if Path(file_path).exists():\n",
    "           image_hash = calculate_hash_val(file_path)\n",
    "           inp_dups[image_hash]=file_path\n",
    "           all_inps[file_path] = image_hash\n",
    "        else:\n",
    "            print('%s is not a valid path, please verify' % file_path)\n",
    "            sys.exit()\n",
    "\n",
    "    find_unique_image(unique_inps, inp_dups)\n",
    "    print(inp_dups)\n",
    "    remove_duplicate_image(all_inps, unique_inps)\n",
    "# if __name__ == '__main__':\n",
    "#     datetime1 = datetime.datetime.now()\n",
    "#     rmv_dup_process(input_image)\n",
    "#     datetime2 = datetime.datetime.now()\n",
    "\n",
    "#     print( \"processed in\",str(datetime2 - datetime1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     pool = multiprocessing.Pool()\n",
    "#     pool = multiprocessing.Pool(processes=4)\n",
    "#     keys_dict = pool.map(calculate_hash_val, input_image)\n",
    "#     pool.close()\n",
    "    \n",
    "#     inp_dups = dict(zip(keys_dict, input_image))\n",
    "#     all_inps = dict(zip(input_image, keys_dict))\n",
    "\n",
    "#     find_unique_files(unique_inps, inp_dups)\n",
    "#     remove_duplicate_image(all_inps, unique_inps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'d1654cb2f80b9d713590ac1e386ea385': 'images/tj_food.jpg', 'ed79d223357ec81af41f5c00fc449b44': 'images/IMG_7690.jpeg', 'dfd9868db12d2991323042b79a2f5cca': 'images/grasshopper.jpg', '72aed7a61cb2648be8b10ca5a2496ea5': 'images/20220411_075008.jpg', 'c879f14451fc6101af3df0d57770f713': 'images/IMG_8154.jpeg', 'b60d6c992bff4a508a8acc1584da5904': 'images/IMG_8608.jpg', '7b6861aff2aaf71181eb3c30030b199b': 'images/IMG_62722.jpeg', 'd396c1d737c76084fdc6c9bc6e7333cc': 'images/20211204_231330.jpg', '123ca7cac3105201f1688dafd6a09d44': 'images/0331191922a_HDR.jpg', '80ad3ed55a043d66a6ad1bb44d1c2d9c': 'images/IMG_20170413_165525732.jpg', '34491923f4271ee2828aa76dabeddc86': 'images/20220215_143240.jpg', 'adc412ea0fe3dfa08f55fec7eec03633': 'images/IMG_5324.jpeg', '19dc61faad91e4a55f61c69f0893987d': 'images/IMG_8261.jpeg', 'fbccf14d504b7b2dbcb5a5bda75bd93b': 'images/0122211534a_HDR.jpg:Zone.Identifier', 'f5f77b6595f2bc55be7d1c13a421223e': 'images/0210212338a.jpg', '0acdb36ed15ee6803d1577bf0814556e': 'images/IMG_6523.jpeg', '18feebeaa00654129c47ee03f8cdef26': 'images/oranges.jpg', 'c237c09d1d78631007f261720a3fbdf5': 'images/sumo.jpg', 'f3cc4d70cdac46d62650a07f05a2b2e8': 'images/1226210348.gif', 'b4ff338393812a620b3276d5d08c98dd': 'images/stages.png', '52af1457f4a5a905e67de3de5ca941ff': 'images/sesamestreet.jpg', 'ab52dd03ba6f0b09754fed2dac658c46': 'images/hike.jpg', 'e5af4e392f353e33883358425c7c482e': 'images/IMG_5145.jpeg', 'f505a5c090af0cd4fc81d0ba5ccfb37b': 'images/staples_center.jpg', 'c99932163315cbd29fa5f7efc28dc522': 'images/IMG_7408.jpeg', '0b98b17ca2b563a5b02fa236c7ba0023': 'images/IMG_6970.jpeg', 'a1b7f0dd5035b2f82c9a132c4cb9e9f4': 'images/medieval.jpg', '7b1b7f171acf1f0379bcedfbf0a220c9': 'images/IMG_7292.jpeg', 'c74d11660c9560cbf840848f22a0cd75': 'images/20220308_153023.jpg', 'c1fc66f246f2a78061600ab559a00388': 'images/IMG_7673.jpeg', 'f3ae7869b14da4bc3dde59c101cf7f91': 'images/0514201057 (1).jpg', 'abbc5fdd4274e33d6fef26d541bb532b': 'images/20210405_133828.jpg', '36c1b7d0666ce3a7bb28252e1812b033': 'images/20211223_163030.jpg', 'b6cef40d6710c898883e0ed277e50a05': 'images/20210425_031811.jpg', '1726f3a087a33dad071334f1c489495a': 'images/1213202230b~2.jpg', 'b4a3450d531a9e37e27592a9811e22a3': 'images/duma.jpg', 'fc7dfb129bd043e147e1be47e3efbe5a': 'images/IMG_8706.jpg', '76cafac4f737b4d3ec90c3e78f454a04': 'images/IMG_8687.jpg', '08193e274fc019e73da26adf26a8b3a7': 'images/botanical2.jpg', '848767093aad6d63e7a7ba593b5c1bf7': 'images/IMG_6696.jpeg', '8e594904b8551c13dc48241dffbca7fe': 'images/0504211949.jpg', '08a0d9899a8b6236183390bcc86182d6': 'images/IMG_0470.jpg', '64c09c7f351263de6233dcc77f1d8b0f': 'images/20210903_222317.jpg', '60dd53eba0a1b29cc1fa66b9674a597b': 'images/20210204_160056.jpg', '2ad6ba5da3813b4fb1799bc16ac02013': 'images/olive.jpg', 'd5b194c94245c4d5b8dc7fa58c575c08': 'images/0122211534a_HDR.jpg', '41f8b2c94f7f8167d38c531e82e38fcf': 'images/20210204_192522.jpg', '72c6ae9856d3ebc9fbad713a5153d92a': 'images/104B057B-3BF8-4610-BF33-A678EAB5380D.JPG', '0041d6786c30b70342db3fc223247fd4': 'images/20220124_182220.jpg', 'dd4cd704197e5a75264a222565b86fd1': 'images/IMG_6212.jpeg', 'b8d07bd71e80e0c9e8b5f100134d0269': 'images/boat.jpg', '33848eaedef3706fb5db30aefc18d5c8': 'images/20220326_040427.jpg', 'cb5d771650f468febbff390b6e54f4e1': 'images/20220406_195101.jpg', '1c96c7c9e1c1ee1ebb080fb705355cf0': 'images/IMG_5799.jpeg', '092116ea97fac54847e00820fc71943b': 'images/0511211650a_HDR.jpg', '33e7838371ee939f7cc094099de50617': 'images/museum.jpg', 'b7e4ec155950095af500323c9bffd177': 'images/20211229_145410.jpg', '16bd41ae65b654ad433350ed4d061925': 'images/20220426_110709.jpg', 'd8bd5dce99e12abe40ee9eeea5ab821c': 'images/IMG_20170523_044545811.jpg', '7a2546916e261348762e198d22000963': 'images/0201210007.jpg', 'eecd4757924d8c6d81a80003c5444131': 'images/IMG_6816.jpeg', 'fa2f11b2a09a14b612b15bb1d294c9c3': 'images/IMG_3143.jpeg', 'a54ef06d3c8053152829c67619bd8e91': 'images/weird_tree.jpg', 'b8faf624c0ee0fa4cf594d3a34046ea7': 'images/0602211537a_HDR.jpg', 'fd34f33374f2177c07de63a446a8354e': 'images/32B7B192-E638-4DA1-BE40-8F3D604BFD91.jpg', '3d28caed7fa67261973cdfb9f42795df': 'images/IMG_5120.jpeg', '22f3f7dfdc4757fb3e53d6999dfdddfd': 'images/IMG_20161225_104113125_HDR.jpg', '2d4e33661f495ed79cf71d4092566de9': 'images/9A861762-FC04-48B2-8856-011EFE860FD1.JPG', '6e339f692ae4df79fbd13b70fec28ff5': 'images/20220306_134640.jpg', '82d51f2d989cc5f3aeffaad892995537': 'images/IMG_0330.jpg', 'ac40af94497913244c3b9925d7312907': 'images/20210625_124524.jpg', '01dc2a0ab2a4d5ef955fbdc924bc2a10': 'images/haworthia.jpg', 'c6cab63aaf6191db2b7171cfda2064f9': 'images/20220226_032601.jpg', '31b5af7e7d1fa9211c98302df4857f6f': 'images/IMG_8702.jpg', '1acd02f3ee154ccda1af442ec924c58c': 'images/IMG_0036.jpg', '3a6505d3a5548e8fcdf2428d1e8e3b6e': 'images/axle.jpg', 'b5ed7b6b36ab862ba023de4c3c5a0a1e': 'images/63875643497__9606A74B-2196-426D-9BD0-AE33C74BD2F9.jpeg', 'd31f60e8a35fe26e8956c52c80248acc': 'images/20220216_104802_01.jpg', '5b6fc22c603b848ec05e419804946736': 'images/20220410_223143.jpg', '8251bca8a34b8c0a08b431efe632a910': 'images/20211020_002637.jpg', '98901f127b42051f57b9eff8903405e9': 'images/20220423_193426.jpg', '59b09aaa1e3e89c71715dc4bcece57be': 'images/20210930_201145.jpg', 'e9471306cc00a5f7778e3800a992e7d1': 'images/IMG_8087.jpeg', '4eb83ab2e14adbe919f76c5c3ee89f90': 'images/IMG_0399.jpg', '42c4eb188a0ee5c59ae0d46bf3a79a82': 'images/aero_garden.jpg', '0daf3a5439f439f7f1c0dd9ab4e949b3': 'images/IMG_8613.jpg', '0aa2717838e8554d1750346106c89372': 'images/bakery.jpg', '4cd67809565e29bb24071f299f24ed69': 'images/1204211415i.jpg', '45ed2b8bc764c3ce31b1404b12eb20bc': 'images/20210426_174943.jpg', 'f1e58e6844b99289f0dbf88765b0f8c8': 'images/20210718_202525.jpg', '438572d05b769f22b55c28dc0b7513b1': 'images/20220323_192522.jpg', '41fe572c45aa16b68322a05c74a4d8f4': 'images/IMG_0561.jpg', '6e6daa9df7e85905f6c5cc88090e39cb': 'images/broom.jpg', '37f9e7653e53bb7f7fa09411f033ab9c': 'images/20220308_155102.jpg', '96ef4c9584d926b2e15fe175eb2d36e1': 'images/0511201730 (1).jpg', '37addbcdd5227ed51485bca958fb0483': 'images/20220217_130555.jpg', '96a81ea542eaf4560977c64381722cc8': 'images/20211217_1730392.jpg', 'da4069f604a14e513336ba06a32f92c6': 'images/IMG_7922.jpeg', 'ac63d5f91af6859ad9cb60d900948e3c': 'images/0508211212b.jpg', '86707cb342c1f12fc03a1894e198707f': 'images/20220308_153843.jpg', '070985c96778ce6cb8a0f9bf6c26794f': 'images/IMG_2338.jpeg', '25e2d44d087b0697270f533502635d92': 'images/art_selfie.jpg', '2512ca33262bd200f7604d14048c53cb': 'images/lake.jpg', '063af64b7acbe0ed88ebef6be3acbfa6': 'images/pool.jpg', '3625f28647813949a8f197217c963284': 'images/1213202230b.jpg'}\n",
      "processed in 0:00:00.486287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 3. Deleting Duplicate image from Source\n",
    "\n",
    "# Once the unique image are identified, the final step is to delete the remaining duplicate image. The below function is used to delete the duplicates from input folder. it takes two inputs all_inps and unique_inps which contatins file paths and hash values respectively.\n",
    "# This can also be implemented using parallel processing to make the process run faster.\n",
    "#If you are using multiprocessing, you can also update the number of #processes in the file. The default value I used is 4\n",
    "\n",
    "\n",
    "# We will be using the above functions same for both Sequential and Parallel implementation. Please find the code below for both the methods respectively.\n",
    "\n",
    "\n",
    "# METHOD2(Parallel Implementation)\n",
    "# This can also be implemented using parallel processing to make the process run faster, If you want to use Parallel processing, just replace the above Sequential Implementation Logic with the below code:\n",
    "\n",
    "#If you are using multiprocessing, you can also update the number of #processes in the file. The default value I used is 4\n",
    "# if __name__ == '__main__':\n",
    "#     pool = multiprocessing.Pool()\n",
    "#     pool = multiprocessing.Pool(processes=4)\n",
    "#     keys_dict = pool.map(calculate_hash_val, input_image)\n",
    "#     pool.close()\n",
    "    \n",
    "#     inp_dups = dict(zip(keys_dict, input_image))\n",
    "#     all_inps = dict(zip(input_image, keys_dict))\n",
    "\n",
    "#     find_unique_image(unique_inps, inp_dups)\n",
    "#     remove_duplicate_image(all_inps, unique_inps)\n",
    "# That’s it. Please find the github link below for the source code. I will also add couple more implementations of parallel processing in the github repo in the coming days.\n",
    "\n",
    "# https://github.com/KiranKumarChilla/Removing-Duplicate-Docs-Using-Hashing-in-Python\n",
    "\n",
    "7\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab032c7e97ed484981d430b039a31203d1f3965cf011def2f6e266d0c7bcfc69"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
