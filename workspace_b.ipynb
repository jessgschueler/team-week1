{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (978489001.py, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/5x/ph8t_tlx7kb2_w43x1mfvwd80000gn/T/ipykernel_85026/978489001.py\"\u001b[0;36m, line \u001b[0;32m36\u001b[0m\n\u001b[0;31m    inplace= True)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "\n",
    "#read csv file and export to pandas df\n",
    "meta_file = './data/meta_data.csv'\n",
    "meta_df = pd.read_csv(meta_file, header=0)\n",
    "\n",
    "def md5_hash():\n",
    "    def calculate_hash_val(path, block_size=''):\n",
    "        image = open(path, 'rb')\n",
    "        hasher = hashlib.md5()\n",
    "        data = image.read()\n",
    "        while len(data) > 0:\n",
    "            hasher.update(data)\n",
    "            data = image.read()\n",
    "        image.close()\n",
    "        return hasher.hexdigest()\n",
    "    #run calculate_hash_val func over file path column and add to df as 'md5 hash'\n",
    "    meta_df['MD5 Hash'] = meta_df['File Path'].map(calculate_hash_val)\n",
    "    #drop duplicate columns using Md5 Hash\n",
    "    meta_df.drop_duplicates(keep='first', subset='MD5 Hash', inplace = True)\n",
    "\n",
    "md5_hash()\n",
    "\n",
    "# function that finds rows missing meta data and adds them to new dataframe\n",
    "def reject_rows():\n",
    "    reject_df = meta_df[meta_df[['Make', 'Model', 'DateTime']].isna().all(axis=1)]\n",
    "    #writes reject_df to csv file\n",
    "    reject_df.to_csv('data/reject.csv', encoding='utf-8', index=False)\n",
    "\n",
    "# drop rows from main dataframe\n",
    "def drop_na():\n",
    "    meta_df = meta_df.dropna( how='all',\n",
    "                         subset=['Make', 'Model', 'DateTime']\n",
    "                        )\n",
    "\n",
    "gps_data = meta_df[~meta_df['GPSInfo'].isnull()]\n",
    "print(gps_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#function to rename files\n",
    "def file_rename():\n",
    "    #use counter to count up + 1 for every image\n",
    "    count = 10\n",
    "    #for loop that iterates over each image in images\n",
    "    for image in os.listdir('images'):\n",
    "       #rename image file to img_(file number)\n",
    "       \n",
    "        os.rename(f'./images/{image}', f'./images/img_{count}.jpg')\n",
    "        count += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "\n",
    "def thumbs_n_nails():\n",
    "    size = 100, 100\n",
    "    for in_file in glob.glob(\"./images/*.jpg\"):\n",
    "        new = os.path.split(in_file)\n",
    "        new_filepath = os.path.join(new[0], \"thumbnails\", \"thumbnail_\" + new[1])\n",
    "        with Image.open(in_file) as img:\n",
    "            img.thumbnail(size)\n",
    "            img.save(new_filepath)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab032c7e97ed484981d430b039a31203d1f3965cf011def2f6e266d0c7bcfc69"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
