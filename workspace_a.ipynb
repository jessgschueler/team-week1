{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#function to rename files\n",
    "def file_rename():\n",
    "    \"\"\"\n",
    "    Loops over and renames each file in the images directory\n",
    "    \"\"\"\n",
    "    #use counter to count up + 1 for every image\n",
    "    count = 10\n",
    "    #for loop that iterates over each image in images\n",
    "    for image in os.listdir('images'):\n",
    "       #rename image file to img_(file number)\n",
    "       \n",
    "        os.rename(f'./images/{image}', f'./images/img_{count}.jpg')\n",
    "        count += 1\n",
    "file_rename()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exif import Image\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "from csv import DictWriter\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def img_filepaths():\n",
    "    \"\"\"\n",
    "    Returns a list of all the file filepaths in our directory variable.\n",
    "    \"\"\"\n",
    "    directory = \"./images\"\n",
    "    # assigns a string of our images directory to a variable\n",
    "    filepaths = []\n",
    "    # create an empty list for our filepaths to be added to\n",
    "    for image in os.listdir(directory):\n",
    "        # looping over the assigned images directory using os.listdir that lists all files in a directory\n",
    "        i = os.path.join(directory, image)\n",
    "        # this adds the images path to the directory, assigning it to \"i\"\n",
    "        if os.path.isfile(i):\n",
    "            # if \"i\" is a file,\n",
    "            filepaths.append(i)\n",
    "            # append its path to the filepaths list\n",
    "    return filepaths\n",
    "    # gives back our completed filepaths list \n",
    "\n",
    "def dict_convert():\n",
    "    \"\"\"\n",
    "    Returns a list of dictionaries of all of the metadata for a list of items in our file path from img_filepaths().\n",
    "    \"\"\"\n",
    "    dict_list = []\n",
    "    image_names = img_filepaths()\n",
    "    # assign image names as our img_filepaths function\n",
    "    for image in image_names:\n",
    "    # Loop through each image in our directory\n",
    "        try:\n",
    "            image_file = Image.open(image)\n",
    "            # assign image_file as the image file being open.\n",
    "            exifdata = image_file.getexif()\n",
    "            # assign pillow metadata tags onto id fields\n",
    "            file_dict = {}\n",
    "            for tag_id in exifdata:\n",
    "                # loop through the tag_ids (metadata tags)\n",
    "                tag = TAGS.get(tag_id, tag_id)\n",
    "                # acquire the tags and convert them into human readable metadata tags\n",
    "                data = exifdata.get(tag_id)\n",
    "                # get the value attributed to the tags in the metadata\n",
    "                if isinstance(data, bytes):\n",
    "                # check if our data is readable data\n",
    "                    data = data.decode()\n",
    "                # if not readable, decode it.\n",
    "                file_dict[tag] = data\n",
    "                # create a dictionary key-value pair with {metadata tag: data from photo}\n",
    "            name = {'File Path': image}\n",
    "            file_dict.update(name)\n",
    "            dict_list.append(file_dict)\n",
    "            # append the dictionary to our empty list \"dict_list\"\n",
    "        except:\n",
    "        # If the file is not readable by our function, instead of raising a value error. Pass it on through and leave it's dictionary empty.\n",
    "            pass   \n",
    "    return dict_list\n",
    "    # returns our list of dictionaries for each photo.\n",
    "\n",
    "dict_list = dict_convert()\n",
    "# assign our dict_list to our function(dict_convert()) output\n",
    "field_names = ['TileWidth', 'TileLength', 'GPSInfo','ResolutionUnit', 'ExifOffset', 'Make', 'Model', 'Software', 'Orientation', 'DateTime', 'XResolution', 'YResolution', 'HostComputer', 'File Path']\n",
    "# assign our header column names to the second photo in our directory (The first one is Blank [0])\n",
    "with open(\"./data/meta_data.csv\", 'w',newline='') as csvfile:\n",
    "# write to meta_data.csv\n",
    "    writer = DictWriter(csvfile, fieldnames=field_names, extrasaction='ignore')\n",
    "    # to the csv assign the fieldnames as 'field_names' and ignore any data that doesnt fit in our columns(field_names)\n",
    "    writer.writeheader()\n",
    "    # write the header with \"field_names\"\n",
    "    writer.writerows(dict_list)\n",
    "    # write the rows with our dict_list which was the output of our dict_convert() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TileWidth</th>\n",
       "      <th>TileLength</th>\n",
       "      <th>GPSInfo</th>\n",
       "      <th>ResolutionUnit</th>\n",
       "      <th>ExifOffset</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Software</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>XResolution</th>\n",
       "      <th>YResolution</th>\n",
       "      <th>HostComputer</th>\n",
       "      <th>File Path</th>\n",
       "      <th>MD5 Hash</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>samsung</td>\n",
       "      <td>SM-G900V</td>\n",
       "      <td>G900VVRU2DQL1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2018-10-11</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/weird_tree.jpg</td>\n",
       "      <td>a54ef06d3c8053152829c67619bd8e91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>samsung</td>\n",
       "      <td>SM-G900V</td>\n",
       "      <td>G900VVRU2DQL1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018-10-25</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/grasshopper2.jpg</td>\n",
       "      <td>dfd9868db12d2991323042b79a2f5cca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>samsung</td>\n",
       "      <td>SM-G900V</td>\n",
       "      <td>G900VVRU2DQL1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-01-13</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/staples_center.jpg</td>\n",
       "      <td>f505a5c090af0cd4fc81d0ba5ccfb37b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>samsung</td>\n",
       "      <td>SM-G900V</td>\n",
       "      <td>G900VVRU2DQL1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2019-03-23</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/sumo.jpg</td>\n",
       "      <td>c237c09d1d78631007f261720a3fbdf5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>762.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>samsung</td>\n",
       "      <td>SM-G970U</td>\n",
       "      <td>G970USQS2BSIV</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2019-11-16</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/tj_food.jpg</td>\n",
       "      <td>d1654cb2f80b9d713590ac1e386ea385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>samsung</td>\n",
       "      <td>SM-G991U1</td>\n",
       "      <td>G991U1UEU2AUC8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/20210425_031811.jpg</td>\n",
       "      <td>b6cef40d6710c898883e0ed277e50a05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>samsung</td>\n",
       "      <td>SM-G970U</td>\n",
       "      <td>G970USQU6GUJ3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/duma.jpg</td>\n",
       "      <td>b4a3450d531a9e37e27592a9811e22a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>Apple</td>\n",
       "      <td>iPhone XR</td>\n",
       "      <td>13.6.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/IMG_5120.jpeg</td>\n",
       "      <td>3d28caed7fa67261973cdfb9f42795df</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>samsung</td>\n",
       "      <td>SM-G991U1</td>\n",
       "      <td>G991U1UES5BVA6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/20220306_134640.jpg</td>\n",
       "      <td>6e339f692ae4df79fbd13b70fec28ff5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>samsung</td>\n",
       "      <td>SM-G900V</td>\n",
       "      <td>G900VVRU2DQL1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>./images/pool.jpg</td>\n",
       "      <td>063af64b7acbe0ed88ebef6be3acbfa6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     TileWidth  TileLength  GPSInfo  ResolutionUnit  ExifOffset     Make  \\\n",
       "65         NaN         NaN   3152.0             2.0       238.0  samsung   \n",
       "3          NaN         NaN   3152.0             2.0       238.0  samsung   \n",
       "24         NaN         NaN   3152.0             2.0       238.0  samsung   \n",
       "17         NaN         NaN   3152.0             2.0       238.0  samsung   \n",
       "1          NaN         NaN    762.0             2.0       238.0  samsung   \n",
       "..         ...         ...      ...             ...         ...      ...   \n",
       "34         NaN         NaN      NaN             2.0       228.0  samsung   \n",
       "37         NaN         NaN      NaN             2.0       226.0  samsung   \n",
       "69         NaN         NaN      NaN             2.0       170.0    Apple   \n",
       "73         NaN         NaN      NaN             2.0       228.0  samsung   \n",
       "110        NaN         NaN   3152.0             2.0       238.0  samsung   \n",
       "\n",
       "         Model        Software  Orientation    DateTime  XResolution  \\\n",
       "65    SM-G900V   G900VVRU2DQL1          6.0  2018-10-11         72.0   \n",
       "3     SM-G900V   G900VVRU2DQL1          1.0  2018-10-25         72.0   \n",
       "24    SM-G900V   G900VVRU2DQL1          1.0  2019-01-13         72.0   \n",
       "17    SM-G900V   G900VVRU2DQL1          1.0  2019-03-23         72.0   \n",
       "1     SM-G970U   G970USQS2BSIV          6.0  2019-11-16         72.0   \n",
       "..         ...             ...          ...         ...          ...   \n",
       "34   SM-G991U1  G991U1UEU2AUC8          6.0         NaN         72.0   \n",
       "37    SM-G970U   G970USQU6GUJ3          1.0         NaN         72.0   \n",
       "69   iPhone XR          13.6.1          NaN         NaN         72.0   \n",
       "73   SM-G991U1  G991U1UES5BVA6          1.0         NaN         72.0   \n",
       "110   SM-G900V   G900VVRU2DQL1          1.0         NaN         72.0   \n",
       "\n",
       "     YResolution HostComputer                     File Path  \\\n",
       "65          72.0          NaN       ./images/weird_tree.jpg   \n",
       "3           72.0          NaN     ./images/grasshopper2.jpg   \n",
       "24          72.0          NaN   ./images/staples_center.jpg   \n",
       "17          72.0          NaN             ./images/sumo.jpg   \n",
       "1           72.0          NaN          ./images/tj_food.jpg   \n",
       "..           ...          ...                           ...   \n",
       "34          72.0          NaN  ./images/20210425_031811.jpg   \n",
       "37          72.0          NaN             ./images/duma.jpg   \n",
       "69          72.0          NaN        ./images/IMG_5120.jpeg   \n",
       "73          72.0          NaN  ./images/20220306_134640.jpg   \n",
       "110         72.0          NaN             ./images/pool.jpg   \n",
       "\n",
       "                             MD5 Hash  \n",
       "65   a54ef06d3c8053152829c67619bd8e91  \n",
       "3    dfd9868db12d2991323042b79a2f5cca  \n",
       "24   f505a5c090af0cd4fc81d0ba5ccfb37b  \n",
       "17   c237c09d1d78631007f261720a3fbdf5  \n",
       "1    d1654cb2f80b9d713590ac1e386ea385  \n",
       "..                                ...  \n",
       "34   b6cef40d6710c898883e0ed277e50a05  \n",
       "37   b4a3450d531a9e37e27592a9811e22a3  \n",
       "69   3d28caed7fa67261973cdfb9f42795df  \n",
       "73   6e339f692ae4df79fbd13b70fec28ff5  \n",
       "110  063af64b7acbe0ed88ebef6be3acbfa6  \n",
       "\n",
       "[78 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import datetime\n",
    "\n",
    "#read csv file and export to pandas df\n",
    "meta_file = './data/meta_data.csv'\n",
    "meta_df = pd.read_csv(meta_file, header=0)\n",
    "\n",
    "def md5_hash():\n",
    "    def calculate_hash_val(path, block_size=''):\n",
    "        image = open(path, 'rb')\n",
    "        hasher = hashlib.md5()\n",
    "        data = image.read()\n",
    "        while len(data) > 0:\n",
    "            hasher.update(data)\n",
    "            data = image.read()\n",
    "        image.close()\n",
    "        return hasher.hexdigest()\n",
    "    #run calculate_hash_val func over file path column and add to df as 'md5 hash'\n",
    "    meta_df['MD5 Hash'] = meta_df['File Path'].map(calculate_hash_val)\n",
    "    #drop duplicate columns using Md5 Hash\n",
    "    meta_df.drop_duplicates(keep='first', subset='MD5 Hash', inplace = True)\n",
    "\n",
    "md5_hash()\n",
    "\n",
    "# function that finds rows missing meta data and adds them to new dataframe\n",
    "def reject_rows():\n",
    "    reject_df = meta_df[meta_df[['Make', 'Model', 'DateTime']].isna().all(axis=1)]\n",
    "    #writes reject_df to csv file\n",
    "    reject_df.to_csv('data/reject.csv', encoding='utf-8', index=False)\n",
    "\n",
    "reject_rows()\n",
    "\n",
    "def drop_na():\n",
    "    meta_df.dropna(axis=0, how='all', subset=['Make', 'Model', 'DateTime'], inplace= True)\n",
    "    return meta_df\n",
    "\n",
    "drop_na()\n",
    "\n",
    "def date_format():\n",
    "    \"\"\"\n",
    "    Performs a mapper using remove_time() to sort all DateTime columns and then write to a new csv file\n",
    "    \"\"\"\n",
    "    def remove_time(value):\n",
    "        \"\"\"\n",
    "        Removes the time from a DateTime column\n",
    "        \"\"\"\n",
    "    # Define inner function to act on the DateTime column\n",
    "        date = value\n",
    "        # assign the DateTime column value to date\n",
    "        try:\n",
    "            date = datetime.datetime.strptime(str(value), '%Y:%m:%d %H:%M:%S').date()\n",
    "            # format column date with only the date returned, with hours, minutes, seconds removed\n",
    "        except:\n",
    "            pass\n",
    "        return date\n",
    "    meta_df[\"DateTime\"] = meta_df[\"DateTime\"].map(remove_time)\n",
    "    # use .map to call remove_time() on all DateTime columns\n",
    "    date_sorted_df = meta_df.sort_values([\"DateTime\"])\n",
    "    # assign variable to sorted dates from earliest to newest\n",
    "    date_sorted_df.to_csv(\"data/sorted.csv\", encoding=\"utf-8\", index=False)\n",
    "    # write sorted rows to a new dataframe\n",
    "    return date_sorted_df\n",
    "\n",
    "date_format()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "\n",
    "def thumbs_n_nails():\n",
    "    \"\"\"\n",
    "    Create a new directory and adds a resized version of each image in the images directory to it\n",
    "    \"\"\"\n",
    "    size = 100, 100\n",
    "    # define size variable with value 100, 100 to later be used\n",
    "    os.mkdir('./images/thumbnails')\n",
    "    # make a new directory in images called thumbnails\n",
    "    try:\n",
    "        for in_file in glob.glob(\"./images/*.jpg\"):\n",
    "            # loop through each file in images with .jpg extension\n",
    "            new = os.path.split(in_file)\n",
    "            # access and split the current files filepath to manipulate\n",
    "            new_filepath = os.path.join(new[0], \"thumbnails\", \"thumbnail_\" + new[1])\n",
    "            # make new filepath\n",
    "            with Image.open(in_file) as img:\n",
    "                # open the current file image\n",
    "                img.thumbnail(size)\n",
    "                # resize current file image as a thumbnail\n",
    "                img.save(new_filepath)\n",
    "                # and save to the new path\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "thumbs_n_nails()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e51396d4ca4f74a9b4edc98dd63d65fa976c9af2686c8d7188ca90947889bf33"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
