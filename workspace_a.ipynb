{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#function to rename files\n",
    "def file_rename():\n",
    "    #use counter to count up + 1 for every image\n",
    "    count = 10\n",
    "    #for loop that iterates over each image in images\n",
    "    for image in os.listdir('images'):\n",
    "       #rename image file to img_(file number)\n",
    "       \n",
    "        os.rename(f'./images/{image}', f'./images/img_{count}.jpg')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exif import Image\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "from csv import DictWriter\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def img_filepaths():\n",
    "    \"\"\"\n",
    "    Returns a list of all the file filepaths in our directory variable.\n",
    "    \"\"\"\n",
    "    directory = \"./images\"\n",
    "    filepaths = []\n",
    "    for image in os.listdir(directory):\n",
    "        i = os.path.join(directory, image)\n",
    "        if os.path.isfile(i):\n",
    "            filepaths.append(i)\n",
    "    return filepaths\n",
    "\n",
    "def dict_convert():\n",
    "    \"\"\"\n",
    "    Returns a list of dictionaries of all of the metadata for a list of items in our file path from img_filepaths().\n",
    "    \"\"\"\n",
    "    dict_list = []\n",
    "    image_names = img_filepaths()\n",
    "    # assign image names as our img_filepaths function\n",
    "    for image in image_names:\n",
    "    # Loop through each image in our directory\n",
    "        try:\n",
    "            image_file = Image.open(image)\n",
    "            # assign image_file as the image file being open.\n",
    "            exifdata = image_file.getexif()\n",
    "            # assign pillow metadata tags onto id fields\n",
    "            file_dict = {}\n",
    "            for tag_id in exifdata:\n",
    "                # loop through the tag_ids (metadata tags)\n",
    "                tag = TAGS.get(tag_id, tag_id)\n",
    "                # acquire the tags and convert them into human readable metadata tags\n",
    "                data = exifdata.get(tag_id)\n",
    "                # get the value attributed to the tags in the metadata\n",
    "                if isinstance(data, bytes):\n",
    "                # check if our data is readable data\n",
    "                    data = data.decode()\n",
    "                # if not readable, decode it.\n",
    "                file_dict[tag] = data\n",
    "                # create a dictionary key-value pair with {metadata tag: data from photo}\n",
    "            name = {'File Path': image}\n",
    "            file_dict.update(name)\n",
    "            dict_list.append(file_dict)\n",
    "            # append the dictionary to our empty list \"dict_list\"\n",
    "        except:\n",
    "        # If the file is not readable by our function, instead of raising a value error. Pass it on through and leave it's dictionary empty.\n",
    "            pass   \n",
    "    return dict_list\n",
    "    # returns our list of dictionaries for each photo.\n",
    "\n",
    "print(dict_list)\n",
    "\n",
    "dict_list = dict_convert()\n",
    "# assign our dict_list to our function(dict_convert()) output\n",
    "field_names = ['TileWidth', 'TileLength', 'GPSInfo','ResolutionUnit', 'ExifOffset', 'Make', 'Model', 'Software', 'Orientation', 'DateTime', 'XResolution', 'YResolution', 'HostComputer', 'File Path']\n",
    "# assign our header column names to the second photo in our directory (The first one is Blank [0])\n",
    "print(field_names)\n",
    "with open(\"./data/meta_data.csv\", 'w',newline='') as csvfile:\n",
    "# write to meta_data.csv\n",
    "    writer = DictWriter(csvfile, fieldnames=field_names, extrasaction='ignore')\n",
    "    # to the csv assign the fieldnames as 'field_names' and ignore any data that doesnt fit in our columns(field_names)\n",
    "    writer.writeheader()\n",
    "    # write the header with \"field_names\"\n",
    "    writer.writerows(dict_list)\n",
    "    # write the rows with our dict_list which was the output of our dict_convert() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def date_format():\n",
    "    metadata_file = \"./data/meta_data.csv\"\n",
    "    metadata = pd.read_csv(metadata_file, header=0)\n",
    "    def remove_time(value):\n",
    "        date = value\n",
    "        try:\n",
    "            date = datetime.datetime.strptime(str(value), '%Y:%m:%d %H:%M:%S').date()\n",
    "        except:\n",
    "            pass\n",
    "        return date\n",
    "    metadata[\"DateTime\"] = metadata[\"DateTime\"].map(remove_time)\n",
    "    date_sorted = metadata.sort_values([\"DateTime\"])\n",
    "    return date_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "\n",
    "def thumbs_n_nails():\n",
    "    size = 100, 100\n",
    "    for in_file in glob.glob(\"./images/*.jpg\"):\n",
    "        new = os.path.split(in_file)\n",
    "        new_filepath = os.path.join(new[0], \"thumbnails\", \"thumbnail_\" + new[1])\n",
    "        with Image.open(in_file) as img:\n",
    "            img.thumbnail(size)\n",
    "            img.save(new_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hashlib\n",
    "\n",
    "#read csv file and export to pandas df\n",
    "meta_file = './data/meta_data.csv'\n",
    "meta_df = pd.read_csv(meta_file, header=0)\n",
    "\n",
    "def md5_hash():\n",
    "    def calculate_hash_val(path, block_size=''):\n",
    "        image = open(path, 'rb')\n",
    "        hasher = hashlib.md5()\n",
    "        data = image.read()\n",
    "        while len(data) > 0:\n",
    "            hasher.update(data)\n",
    "            data = image.read()\n",
    "        image.close()\n",
    "        return hasher.hexdigest()\n",
    "    #run calculate_hash_val func over file path column and add to df as 'md5 hash'\n",
    "    meta_df['MD5 Hash'] = meta_df['File Path'].map(calculate_hash_val)\n",
    "    #drop duplicate columns using Md5 Hash\n",
    "    meta_df.drop_duplicates(keep='first', subset='MD5 Hash', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that finds rows missing meta data and adds them to new dataframe\n",
    "def reject_rows():\n",
    "    reject_df = meta_df[meta_df[['Make', 'Model', 'DateTime']].isna().all(axis=1)]\n",
    "    #writes reject_df to csv file\n",
    "    reject_df.to_csv('data/reject.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd4fb600c96b24893411e3e39fa46262c773a079f36165bf4db4cf2e98b78b86"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
